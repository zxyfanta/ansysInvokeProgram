# 激光毁伤仿真系统部署与运维方案

## 1. 部署架构设计

### 1.1 部署环境分层

```
┌─────────────────────────────────────────────────────────────┐
│                    生产环境 (Production)                      │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 负载均衡器   │ │ 应用服务器   │ │ 数据库服务器 │           │
│  │   (LB)      │ │   (App)     │ │    (DB)     │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    预生产环境 (Staging)                       │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 应用服务器   │ │ 数据库服务器 │ │ 监控服务器   │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    测试环境 (Testing)                        │
│  ┌─────────────┐ ┌─────────────┐                           │
│  │ 应用服务器   │ │ 数据库服务器 │                           │
│  └─────────────┘ └─────────────┘                           │
├─────────────────────────────────────────────────────────────┤
│                    开发环境 (Development)                    │
│  ┌─────────────┐                                           │
│  │ 本地开发环境 │                                           │
│  └─────────────┘                                           │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 容器化部署方案

#### 1.2.1 Docker镜像构建
```dockerfile
# deployment/docker/Dockerfile
FROM ubuntu:20.04

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV ANSYS_ROOT=/opt/ansys_inc/v211

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    python3.8 \
    python3-pip \
    python3-dev \
    build-essential \
    libgl1-mesa-glx \
    libglu1-mesa \
    libxt6 \
    libxext6 \
    libxrender1 \
    libxtst6 \
    && rm -rf /var/lib/apt/lists/*

# 创建应用目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY src/ ./src/
COPY config/ ./config/
COPY data/ ./data/
COPY setup.py .

# 安装应用
RUN pip3 install -e .

# 创建非root用户
RUN useradd -m -u 1000 simuser && \
    chown -R simuser:simuser /app
USER simuser

# 暴露端口
EXPOSE 8080

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python3 -c "import laser_damage; print('OK')" || exit 1

# 启动命令
CMD ["python3", "-m", "laser_damage.gui.main_window"]
```

#### 1.2.2 Docker Compose配置
```yaml
# deployment/docker/docker-compose.yml
version: '3.8'

services:
  laser-simulation-app:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile
    container_name: laser-simulation-app
    ports:
      - "8080:8080"
    volumes:
      - ../../data:/app/data
      - ../../results:/app/results
      - /opt/ansys_inc:/opt/ansys_inc:ro
      - simulation-logs:/app/logs
    environment:
      - ANSYS_ROOT=/opt/ansys_inc/v211
      - ANSYSLMD_LICENSE_FILE=1055@license-server
      - DATABASE_URL=postgresql://sim_user:${DB_PASSWORD}@database:5432/laser_simulation
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - database
      - redis
    restart: unless-stopped
    networks:
      - simulation-network

  database:
    image: postgres:13
    container_name: laser-simulation-db
    environment:
      - POSTGRES_DB=laser_simulation
      - POSTGRES_USER=sim_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - simulation-network

  redis:
    image: redis:6-alpine
    container_name: laser-simulation-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    networks:
      - simulation-network

  nginx:
    image: nginx:alpine
    container_name: laser-simulation-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - laser-simulation-app
    restart: unless-stopped
    networks:
      - simulation-network

  prometheus:
    image: prom/prometheus:latest
    container_name: laser-simulation-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped
    networks:
      - simulation-network

  grafana:
    image: grafana/grafana:latest
    container_name: laser-simulation-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    restart: unless-stopped
    networks:
      - simulation-network

volumes:
  postgres-data:
  redis-data:
  simulation-logs:
  prometheus-data:
  grafana-data:

networks:
  simulation-network:
    driver: bridge
```

### 1.3 Kubernetes部署方案

#### 1.3.1 应用部署配置
```yaml
# deployment/kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: laser-simulation-deployment
  labels:
    app: laser-simulation
spec:
  replicas: 3
  selector:
    matchLabels:
      app: laser-simulation
  template:
    metadata:
      labels:
        app: laser-simulation
    spec:
      containers:
      - name: laser-simulation
        image: laser-simulation:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "8Gi"
            cpu: "4"
          limits:
            memory: "16Gi"
            cpu: "8"
        env:
        - name: ANSYS_ROOT
          value: "/opt/ansys_inc/v211"
        - name: ANSYSLMD_LICENSE_FILE
          valueFrom:
            secretKeyRef:
              name: ansys-license
              key: server
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: url
        volumeMounts:
        - name: ansys-installation
          mountPath: /opt/ansys_inc
          readOnly: true
        - name: shared-storage
          mountPath: /app/data
        - name: results-storage
          mountPath: /app/results
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: ansys-installation
        hostPath:
          path: /opt/ansys_inc
      - name: shared-storage
        persistentVolumeClaim:
          claimName: simulation-data-pvc
      - name: results-storage
        persistentVolumeClaim:
          claimName: simulation-results-pvc
      nodeSelector:
        node-type: compute-intensive
      tolerations:
      - key: "ansys-licensed"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"

---
apiVersion: v1
kind: Service
metadata:
  name: laser-simulation-service
spec:
  selector:
    app: laser-simulation
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: laser-simulation-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - laser-simulation.company.com
    secretName: laser-simulation-tls
  rules:
  - host: laser-simulation.company.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: laser-simulation-service
            port:
              number: 80
```

## 2. 监控与日志

### 2.1 监控指标体系

#### 2.1.1 系统监控指标
```python
# src/laser_damage/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import psutil
import time

# 业务指标
simulation_counter = Counter('simulations_total', 'Total number of simulations', ['status'])
simulation_duration = Histogram('simulation_duration_seconds', 'Simulation execution time')
active_simulations = Gauge('active_simulations', 'Number of active simulations')
queue_length = Gauge('simulation_queue_length', 'Number of simulations in queue')

# 系统指标
cpu_usage = Gauge('system_cpu_usage_percent', 'CPU usage percentage')
memory_usage = Gauge('system_memory_usage_bytes', 'Memory usage in bytes')
disk_usage = Gauge('system_disk_usage_percent', 'Disk usage percentage')

# ANSYS许可证指标
ansys_licenses_total = Gauge('ansys_licenses_total', 'Total ANSYS licenses')
ansys_licenses_used = Gauge('ansys_licenses_used', 'Used ANSYS licenses')

class MetricsCollector:
    """指标收集器"""
    
    def __init__(self):
        self.start_time = time.time()
        
    def collect_system_metrics(self):
        """收集系统指标"""
        # CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_usage.set(cpu_percent)
        
        # 内存使用
        memory = psutil.virtual_memory()
        memory_usage.set(memory.used)
        
        # 磁盘使用
        disk = psutil.disk_usage('/')
        disk_usage.set(disk.percent)
    
    def record_simulation_start(self):
        """记录仿真开始"""
        active_simulations.inc()
        
    def record_simulation_end(self, status: str, duration: float):
        """记录仿真结束"""
        active_simulations.dec()
        simulation_counter.labels(status=status).inc()
        simulation_duration.observe(duration)
    
    def update_queue_length(self, length: int):
        """更新队列长度"""
        queue_length.set(length)
    
    def start_metrics_server(self, port: int = 8000):
        """启动指标服务器"""
        start_http_server(port)
```

#### 2.1.2 Prometheus配置
```yaml
# deployment/monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'laser-simulation'
    static_configs:
      - targets: ['laser-simulation-app:8000']
    scrape_interval: 10s
    metrics_path: /metrics

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

# 告警规则
# deployment/monitoring/alert_rules.yml
groups:
- name: laser_simulation_alerts
  rules:
  - alert: HighCPUUsage
    expr: system_cpu_usage_percent > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is above 90% for more than 5 minutes"

  - alert: HighMemoryUsage
    expr: system_memory_usage_bytes / (1024*1024*1024) > 14
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is above 14GB for more than 5 minutes"

  - alert: SimulationFailureRate
    expr: rate(simulations_total{status="failed"}[5m]) / rate(simulations_total[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High simulation failure rate"
      description: "Simulation failure rate is above 10%"

  - alert: AnsysLicenseUnavailable
    expr: ansys_licenses_used >= ansys_licenses_total
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "ANSYS licenses exhausted"
      description: "All ANSYS licenses are in use"
```

### 2.2 日志管理

#### 2.2.1 日志配置
```python
# config/logging_config.py
import logging.config
from pathlib import Path

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s',
            'datefmt': '%Y-%m-%d %H:%M:%S'
        },
        'json': {
            'format': '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "line": %(lineno)d, "message": "%(message)s"}',
            'datefmt': '%Y-%m-%dT%H:%M:%S'
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'standard',
        },
        'file': {
            'level': 'DEBUG',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/application.log',
            'formatter': 'json',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 10,
        },
        'error_file': {
            'level': 'ERROR',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/error.log',
            'formatter': 'json',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
        },
        'simulation_file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/simulation.log',
            'formatter': 'json',
            'maxBytes': 52428800,  # 50MB
            'backupCount': 20,
        },
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file', 'error_file'],
            'level': 'DEBUG',
            'propagate': False
        },
        'laser_damage.simulation': {
            'handlers': ['simulation_file'],
            'level': 'INFO',
            'propagate': True
        },
        'ansys': {
            'handlers': ['file'],
            'level': 'WARNING',
            'propagate': True
        },
    }
}

def setup_logging():
    """设置日志配置"""
    # 确保日志目录存在
    Path('logs').mkdir(exist_ok=True)
    
    # 应用日志配置
    logging.config.dictConfig(LOGGING_CONFIG)
```

## 3. 备份与恢复

### 3.1 数据备份策略

#### 3.1.1 自动备份脚本
```bash
#!/bin/bash
# scripts/backup.sh

set -e

# 配置变量
BACKUP_DIR="/backup/laser_simulation"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# 创建备份目录
mkdir -p "$BACKUP_DIR"

echo "开始备份 - $DATE"

# 1. 数据库备份
echo "备份数据库..."
pg_dump laser_simulation > "$BACKUP_DIR/db_$DATE.sql"
gzip "$BACKUP_DIR/db_$DATE.sql"

# 2. 仿真结果备份
echo "备份仿真结果..."
tar -czf "$BACKUP_DIR/results_$DATE.tar.gz" data/results/

# 3. 配置文件备份
echo "备份配置文件..."
tar -czf "$BACKUP_DIR/config_$DATE.tar.gz" config/

# 4. 用户数据备份
echo "备份用户数据..."
tar -czf "$BACKUP_DIR/user_data_$DATE.tar.gz" data/models/ data/materials/

# 5. 清理旧备份
echo "清理旧备份..."
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

# 6. 验证备份
echo "验证备份..."
if [ -f "$BACKUP_DIR/db_$DATE.sql.gz" ] && [ -f "$BACKUP_DIR/results_$DATE.tar.gz" ]; then
    echo "备份完成 - $DATE"
    
    # 发送通知
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"激光仿真系统备份完成: '$DATE'"}' \
        "$SLACK_WEBHOOK_URL"
else
    echo "备份失败 - $DATE"
    exit 1
fi
```

#### 3.1.2 恢复脚本
```bash
#!/bin/bash
# scripts/restore.sh

set -e

if [ $# -ne 1 ]; then
    echo "用法: $0 <备份日期>"
    echo "示例: $0 20240101_120000"
    exit 1
fi

BACKUP_DATE=$1
BACKUP_DIR="/backup/laser_simulation"

echo "开始恢复 - $BACKUP_DATE"

# 1. 停止服务
echo "停止服务..."
docker-compose down

# 2. 恢复数据库
echo "恢复数据库..."
gunzip -c "$BACKUP_DIR/db_$BACKUP_DATE.sql.gz" | psql laser_simulation

# 3. 恢复仿真结果
echo "恢复仿真结果..."
tar -xzf "$BACKUP_DIR/results_$BACKUP_DATE.tar.gz" -C /

# 4. 恢复配置文件
echo "恢复配置文件..."
tar -xzf "$BACKUP_DIR/config_$BACKUP_DATE.tar.gz" -C /

# 5. 恢复用户数据
echo "恢复用户数据..."
tar -xzf "$BACKUP_DIR/user_data_$BACKUP_DATE.tar.gz" -C /

# 6. 启动服务
echo "启动服务..."
docker-compose up -d

echo "恢复完成 - $BACKUP_DATE"
```

## 4. 运维自动化

### 4.1 健康检查

#### 4.1.1 应用健康检查
```python
# src/laser_damage/health/health_check.py
from flask import Flask, jsonify
import psutil
import os
from laser_damage.utils.ansys_utils import AnsysConnector

app = Flask(__name__)

@app.route('/health')
def health_check():
    """基础健康检查"""
    return jsonify({
        'status': 'healthy',
        'timestamp': time.time(),
        'version': '1.0.0'
    })

@app.route('/ready')
def readiness_check():
    """就绪检查"""
    checks = {
        'database': check_database(),
        'ansys': check_ansys(),
        'disk_space': check_disk_space(),
        'memory': check_memory()
    }
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return jsonify({
        'status': 'ready' if all_healthy else 'not_ready',
        'checks': checks
    }), status_code

def check_database():
    """检查数据库连接"""
    try:
        # 数据库连接检查逻辑
        return True
    except Exception:
        return False

def check_ansys():
    """检查ANSYS连接"""
    try:
        connector = AnsysConnector()
        return connector.test_connection()
    except Exception:
        return False

def check_disk_space():
    """检查磁盘空间"""
    disk_usage = psutil.disk_usage('/')
    return disk_usage.percent < 90

def check_memory():
    """检查内存使用"""
    memory = psutil.virtual_memory()
    return memory.percent < 90

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8081)
```

### 4.2 自动扩缩容

#### 4.2.1 HPA配置
```yaml
# deployment/kubernetes/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: laser-simulation-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: laser-simulation-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: simulation_queue_length
      target:
        type: AverageValue
        averageValue: "5"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
```

---

**文档版本**: v1.0  
**创建日期**: 2024-01-01  
**适用范围**: 激光毁伤仿真系统运维团队
